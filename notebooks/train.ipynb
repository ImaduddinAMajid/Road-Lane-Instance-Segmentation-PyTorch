{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tuSimple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHANNELS = 3\n",
    "OUTPUT_CHANNELS = 2\n",
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 100\n",
    "LOG_INTERVAL = 10\n",
    "SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/data/tuSimple/train_set/'\n",
    "test_path = '/data/tuSimple/test_set/'\n",
    "json_0313_path = '/data/tuSimple/train_set/label_data_0313.json'\n",
    "json_0531_path = '/data/tuSimple/train_set/label_data_0531.json'\n",
    "json_0601_path = '/data/tuSimple/train_set/label_data_0601.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.tuSimpleDataset(train_path, size=SIZE)\n",
    "test_dataset = dataset.tuSimpleDataset(test_path, size=SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imgs, labels = next(iter(train_dataloader))\n",
    "imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "out = torchvision.utils.make_grid(imgs)\n",
    "out = out.numpy().transpose((1, 2, 0))\n",
    "plt.figure(dpi=300)\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinSegNet(nn.Module):\n",
    "    # refer from : https://github.com/delta-onera/segnet_pytorch/blob/master/segnet.py\n",
    "    def __init__(self, input_ch, output_ch):\n",
    "        super(BinSegNet, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv11 = nn.Conv2d(in_channels=input_ch, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(64)\n",
    "        self.conv12 = nn.Conv2d(64 ,64, kernel_size=3, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn21 = nn.BatchNorm2d(128)\n",
    "        self.conv22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn22 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn31 = nn.BatchNorm2d(256)\n",
    "        self.conv32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn32 = nn.BatchNorm2d(256)\n",
    "        self.conv33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn33 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn41 = nn.BatchNorm2d(512)\n",
    "        self.conv42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn42 = nn.BatchNorm2d(512)\n",
    "        self.conv43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn43 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn51 = nn.BatchNorm2d(512)\n",
    "        self.conv52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn52 = nn.BatchNorm2d(512)\n",
    "        self.conv53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn53 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # Decoder\n",
    "        self.conv53d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn53d = nn.BatchNorm2d(512)\n",
    "        self.conv52d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn52d = nn.BatchNorm2d(512)\n",
    "        self.conv51d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn51d = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv43d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn43d = nn.BatchNorm2d(512)\n",
    "        self.conv42d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn42d = nn.BatchNorm2d(512)\n",
    "        self.conv41d = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.bn41d = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv33d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn33d = nn.BatchNorm2d(256)\n",
    "        self.conv32d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn32d = nn.BatchNorm2d(256)\n",
    "        self.conv31d = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn31d = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv22d = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn22d = nn.BatchNorm2d(128)\n",
    "        self.conv21d = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.bn21d = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv12d = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn12d = nn.BatchNorm2d(64)\n",
    "        self.conv11d = nn.Conv2d(64, output_ch, kernel_size=3, padding=1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = F.relu(self.bn11(self.conv11(x)))\n",
    "        x = F.relu(self.bn12(self.conv12(x)))\n",
    "        x, ind_1 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        x = F.relu(self.bn21(self.conv21(x)))\n",
    "        x = F.relu(self.bn22(self.conv22(x)))\n",
    "        x, ind_2 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        x = F.relu(self.bn31(self.conv31(x)))\n",
    "        x = F.relu(self.bn32(self.conv32(x)))\n",
    "        x = F.relu(self.bn33(self.conv33(x)))\n",
    "        x, ind_3 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        x = F.relu(self.bn41(self.conv41(x)))\n",
    "        x = F.relu(self.bn42(self.conv42(x)))\n",
    "        x = F.relu(self.bn43(self.conv43(x)))\n",
    "        x, ind_4 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        x = F.relu(self.bn51(self.conv51(x)))\n",
    "        x = F.relu(self.bn52(self.conv52(x)))\n",
    "        x = F.relu(self.bn53(self.conv53(x)))\n",
    "        x, ind_5 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        # Decoder\n",
    "        x = F.max_unpool2d(x, ind_5, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.bn53d(self.conv53d(x)))\n",
    "        x = F.relu(self.bn52d(self.conv52d(x)))\n",
    "        x = F.relu(self.bn51d(self.conv51d(x)))\n",
    "        \n",
    "        x = F.max_unpool2d(x, ind_4, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.bn43d(self.conv43d(x)))\n",
    "        x = F.relu(self.bn42d(self.conv42d(x)))\n",
    "        x = F.relu(self.bn41d(self.conv41d(x)))\n",
    "        \n",
    "        x = F.max_unpool2d(x, ind_3, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.bn33d(self.conv33d(x)))\n",
    "        x = F.relu(self.bn32d(self.conv32d(x)))\n",
    "        x = F.relu(self.bn31d(self.conv31d(x)))\n",
    "        \n",
    "        x = F.max_unpool2d(x, ind_2, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.bn22d(self.conv22d(x)))\n",
    "        x = F.relu(self.bn21d(self.conv21d(x)))\n",
    "        \n",
    "        x = F.max_unpool2d(x, ind_1, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.bn12d(self.conv12d(x)))\n",
    "        x = self.conv11d(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # refer from : https://github.com/Sayan98/pytorch-segnet/blob/master/src/train.py\n",
    "    is_better = True\n",
    "    prev_loss = float('inf')\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        t_start = time.time()\n",
    "        loss_f = 0\n",
    "        \n",
    "        for batch_idx, (imgs, labels) in enumerate(train_dataloader):\n",
    "            \n",
    "\n",
    "            input_tensor = torch.autograd.Variable(imgs).cuda()\n",
    "            target_tensor = torch.autograd.Variable(labels).cuda()\n",
    "            \n",
    "            softmaxed_tensor = model(input_tensor)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(softmaxed_tensor, target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_f += loss.float()\n",
    "            prediction_f = softmaxed_tensor.float()\n",
    "            \n",
    "            if batch_idx % LOG_INTERVAL == 0:\n",
    "                print('\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(imgs), len(train_dataloader.dataset),\n",
    "                    100. * batch_idx / len(train_dataloader), loss.item()))\n",
    "            \n",
    "        dt = time.time() - t_start\n",
    "        is_better = loss_f < prev_loss\n",
    "        \n",
    "        if is_better:\n",
    "            prev_loss = loss_f\n",
    "            torch.save(model.state_dict(), \"model_best.pth\")\n",
    "            \n",
    "        print(\"Epoch #{}\\tLoss: {:.8f}\\t Time: {:2f}s\".format(epoch+1, loss_f, dt))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "model = BinSegNet(input_ch=INPUT_CHANNELS, output_ch=OUTPUT_CHANNELS).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
